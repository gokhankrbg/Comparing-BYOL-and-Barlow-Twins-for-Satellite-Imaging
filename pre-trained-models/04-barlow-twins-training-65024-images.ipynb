{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6fc2cd0",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-28T23:28:27.474493Z",
     "iopub.status.busy": "2025-06-28T23:28:27.474280Z"
    },
    "papermill": {
     "duration": 43200.004547,
     "end_time": "2025-06-29T11:28:27.475886",
     "exception": false,
     "start_time": "2025-06-28T23:28:27.471339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/205.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m204.8/205.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.4/205.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/8.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/8.8 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m8.4/8.8 MB\u001b[0m \u001b[31m132.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m8.4/8.8 MB\u001b[0m \u001b[31m132.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m8.4/8.8 MB\u001b[0m \u001b[31m132.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/53.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.7/53.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Pre-loading images into RAM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d016affb0b43461c89dca029700de20f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading files:   0%|          | 0/241 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Initialized: Using 50% of data. -> Pre-loaded 61,696 images.\n",
      "Using ResNet-18 as the encoder model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Resuming from checkpoint: /kaggle/input/04-barlow-twins-50pct/barlow_checkpoint_50pct.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -> Resuming training from the start of epoch 8\n",
      "\n",
      "--- Resuming Barlow Twins Training from Epoch 8 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d736bbcc3eff4ba1a65c2d8b6879babd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/30:   0%|          | 0/482 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Summary: Average Loss = 663.90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 663.899121). Saving best model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c0b0842ff24bd894093236d9c157a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/30:   0%|          | 0/482 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Summary: Average Loss = 619.46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (663.899121 --> 619.456833). Saving best model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fd66f0d52434bb59a8af38128ee989f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/30:   0%|          | 0/482 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Summary: Average Loss = 583.80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (619.456833 --> 583.804136). Saving best model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf91fd0d067c410bb1c8719eeab50aaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/30:   0%|          | 0/482 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Summary: Average Loss = 557.73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (583.804136 --> 557.726988). Saving best model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "434e47fbb6af4611808d6c5a28275963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/30:   0%|          | 0/482 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Summary: Average Loss = 535.54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (557.726988 --> 535.536615). Saving best model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a2390ef4c5f4092bc047a1e5811bcda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/30:   0%|          | 0/482 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Summary: Average Loss = 515.72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (535.536615 --> 515.722460). Saving best model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "332ce2d42ff64c3dadc6e45cb95fa48f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/30:   0%|          | 0/482 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Summary: Average Loss = 499.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (515.722460 --> 499.110033). Saving best model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50a77c4bcc8e4bdfabcabd91ed036f7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/30:   0%|          | 0/482 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Summary: Average Loss = 484.36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (499.110033 --> 484.361633). Saving best model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b1f5a4bc3604c5784551bc5e749de8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/30:   0%|          | 0/482 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Summary: Average Loss = 470.28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (484.361633 --> 470.281585). Saving best model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69eb4659acc74256aeda0b82ada19890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/30:   0%|          | 0/482 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 04b - RESUME BARLOW TWINS TRAINING (ON NEW ACCOUNT)\n",
    "# ==============================================================================\n",
    "# Purpose: To resume the Barlow Twins training from a checkpoint generated\n",
    "#          by a different Kaggle account's notebook version.\n",
    "# ==============================================================================\n",
    "\n",
    "# --- 0. Imports ---\n",
    "!pip install \"zarr>=2.10.0\" numcodecs -q\n",
    "import torch, torch.nn as nn, torch.nn.functional as F, torchvision.transforms as T, torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "import numpy as np, zarr, random, math, os, copy, zipfile, tempfile, gc\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# --- 1. Configuration ---\n",
    "CONFIG = {\n",
    "    'data_path': \"/kaggle/input/01-data-preparation/data/ssl4eo-s12/train/S2RGB\",\n",
    "    'checkpoint_input_folder': '04-barlow-twins-50pct', \n",
    "    'output_dir': \"/kaggle/working/\",\n",
    "    'epochs': 30,\n",
    "    'batch_size': 128,\n",
    "    'learning_rate': 1e-3,\n",
    "    'weight_decay': 1.5e-6,\n",
    "    'image_size': 224,\n",
    "    'projection_dim': 2048,\n",
    "    'hidden_dim': 4096,\n",
    "    'lambda_param': 5e-3,\n",
    "    'num_workers': 2,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'early_stopping_patience': 10,\n",
    "    'data_subset_percentage': 0.50,\n",
    "    'checkpoint_filename': \"barlow_checkpoint_50pct.pth\",\n",
    "    'best_model_filename': \"barlow_best_encoder_50pct.pth\"\n",
    "}\n",
    "\n",
    "# --- 2. Helper Classes & Functions ---\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=True, delta=0):\n",
    "        self.patience, self.verbose, self.delta = patience, verbose, delta\n",
    "        self.counter, self.best_score, self.early_stop, self.val_loss_min = 0, None, False, np.Inf\n",
    "    def __call__(self, val_loss, model, path):\n",
    "        if not math.isfinite(val_loss): print(\"Loss is not finite, stopping.\"); self.early_stop = True; return\n",
    "        score = -val_loss\n",
    "        if self.best_score is None: self.best_score = score; self.save_checkpoint(val_loss, model, path)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose: print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience: self.early_stop = True\n",
    "        else: self.best_score = score; self.save_checkpoint(val_loss, model, path); self.counter = 0\n",
    "    def save_checkpoint(self, val_loss, model, path):\n",
    "        if self.verbose: print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving best model...')\n",
    "        torch.save(model.encoder.state_dict(), path); self.val_loss_min = val_loss\n",
    "\n",
    "def save_checkpoint(epoch, model, optimizer, scheduler, loss, config):\n",
    "    state = {'epoch': epoch + 1, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), 'scheduler_state_dict': scheduler.state_dict(), 'loss': loss}\n",
    "    torch.save(state, os.path.join(config['output_dir'], config['checkpoint_filename']))\n",
    "\n",
    "def load_checkpoint(model, optimizer, scheduler, config):\n",
    "    path = Path(f\"/kaggle/input/{config['checkpoint_input_folder']}/{config['checkpoint_filename']}\")\n",
    "    start_epoch = 0\n",
    "    if path.exists():\n",
    "        print(f\"✅ Resuming from checkpoint: {path}\")\n",
    "        ckpt = torch.load(path, map_location=config['device'])\n",
    "        model.load_state_dict(ckpt['model_state_dict']); optimizer.load_state_dict(ckpt['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(ckpt['scheduler_state_dict']); start_epoch = ckpt['epoch']\n",
    "        print(f\"   -> Resuming training from the start of epoch {start_epoch}\")\n",
    "    else: print(f\"❌ Checkpoint not found at {path}. Cannot resume.\")\n",
    "    return start_epoch\n",
    "\n",
    "# --- 3. Dataset, Model, and Loss ---\n",
    "class SSL4EODataset(Dataset):\n",
    "    def __init__(self, root_dir, subset_percentage=1.0):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        all_zarr_files = sorted(list(self.root_dir.glob(\"*.zarr.zip\")))\n",
    "        num_files_to_use = int(len(all_zarr_files) * subset_percentage)\n",
    "        self.zarr_files = random.sample(all_zarr_files, num_files_to_use) if subset_percentage < 1.0 else all_zarr_files\n",
    "        self.images = self._preload_images(); self.total_images = len(self.images)\n",
    "        print(f\"\\nDataset Initialized: Using {subset_percentage*100:.0f}% of data. -> Pre-loaded {self.total_images:,} images.\")\n",
    "        self.transform = T.Compose([\n",
    "            T.ToPILImage(), T.RandomResizedCrop(CONFIG['image_size'], antialias=True), T.RandomHorizontalFlip(),\n",
    "            T.ColorJitter(0.4, 0.4, 0.2, 0.1), T.RandomGrayscale(p=0.2), T.GaussianBlur(23, (0.1, 2.0)),\n",
    "            T.ToTensor(), T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "    def _preload_images(self):\n",
    "        images = []; print(\"Pre-loading images into RAM...\")\n",
    "        for fp in tqdm(self.zarr_files, desc=\"Loading files\"):\n",
    "            with tempfile.TemporaryDirectory() as td:\n",
    "                with zipfile.ZipFile(str(fp), 'r') as zf: zf.extractall(td)\n",
    "                za = zarr.open(td, mode='r')['bands'][:]; images.extend(za.reshape(-1, *za.shape[2:]))\n",
    "        return images\n",
    "    def __len__(self): return self.total_images\n",
    "    def __getitem__(self, idx):\n",
    "        image_chw = self.images[idx]; image_hwc = np.transpose(image_chw, (1, 2, 0))\n",
    "        view1 = self.transform(image_hwc); view2 = self.transform(image_hwc)\n",
    "        return view1, view2\n",
    "\n",
    "class BarlowTwinsModel(nn.Module):\n",
    "    def __init__(self, encoder, encoder_dim, projection_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(encoder_dim, hidden_dim), nn.BatchNorm1d(hidden_dim), nn.ReLU(True),\n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.BatchNorm1d(hidden_dim), nn.ReLU(True),\n",
    "            nn.Linear(hidden_dim, projection_dim))\n",
    "    def forward(self, v1, v2):\n",
    "        z1 = self.projector(self.encoder(v1)); z2 = self.projector(self.encoder(v2))\n",
    "        return z1, z2\n",
    "\n",
    "def barlow_twins_loss_fn(z1, z2, lambda_param):\n",
    "    batch_size = z1.shape[0]\n",
    "    z1_norm = (z1 - z1.mean(dim=0)) / (z1.std(dim=0) + 1e-5)\n",
    "    z2_norm = (z2 - z2.mean(dim=0)) / (z2.std(dim=0) + 1e-5)\n",
    "    c = (z1_norm.T @ z2_norm) / batch_size\n",
    "    on_diag_loss = ((torch.diagonal(c) - 1)**2).sum()\n",
    "    off_diag = c.fill_diagonal_(0)\n",
    "    off_diag_loss = (off_diag**2).sum()\n",
    "    return on_diag_loss + lambda_param * off_diag_loss\n",
    "\n",
    "# --- 4. Main Training Execution ---\n",
    "if __name__ == '__main__':\n",
    "    gc.collect(); torch.cuda.empty_cache()\n",
    "    device = torch.device(CONFIG['device']); print(f\"Using device: {device}\")\n",
    "    \n",
    "    dataset = SSL4EODataset(CONFIG['data_path'], CONFIG['data_subset_percentage'])\n",
    "    loader = DataLoader(dataset, batch_size=CONFIG['batch_size'], shuffle=True, \n",
    "                        num_workers=CONFIG['num_workers'], pin_memory=True, drop_last=True)\n",
    "    \n",
    "    print(\"Using ResNet-18 as the encoder model.\")\n",
    "    resnet = models.resnet18(weights=None); encoder_output_dim = resnet.fc.in_features; resnet.fc = nn.Identity()\n",
    "    \n",
    "    model = BarlowTwinsModel(\n",
    "        encoder=resnet, encoder_dim=encoder_output_dim,\n",
    "        projection_dim=CONFIG['projection_dim'], hidden_dim=CONFIG['hidden_dim']\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=CONFIG['learning_rate'], weight_decay=CONFIG['weight_decay'])\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(loader)*CONFIG['epochs'])\n",
    "    \n",
    "    early_stopper = EarlyStopping(patience=CONFIG['early_stopping_patience'], verbose=True)\n",
    "    \n",
    "    # This will load the state from the previous 12-hour run\n",
    "    start_epoch = load_checkpoint(model, optimizer, scheduler, CONFIG)\n",
    "    \n",
    "    if start_epoch > 0:\n",
    "        print(f\"\\n--- Resuming Barlow Twins Training from Epoch {start_epoch} ---\")\n",
    "        # The training loop starts from the next epoch\n",
    "        for epoch in range(start_epoch, CONFIG['epochs']):\n",
    "            model.train(); total_loss = 0.0\n",
    "            pbar = tqdm(loader, desc=f\"Epoch {epoch+1}/{CONFIG['epochs']}\")\n",
    "            for view1, view2 in pbar:\n",
    "                view1, view2 = view1.to(device), view2.to(device)\n",
    "                z1, z2 = model(view1, view2)\n",
    "                loss = barlow_twins_loss_fn(z1, z2, lambda_param=CONFIG['lambda_param'])\n",
    "                \n",
    "                optimizer.zero_grad(); loss.backward(); optimizer.step(); scheduler.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                pbar.set_postfix({'Loss': f\"{loss.item():.2f}\", 'LR': f\"{optimizer.param_groups[0]['lr']:.6f}\"})\n",
    "\n",
    "            avg_loss = total_loss / len(loader)\n",
    "            print(f\"Epoch {epoch+1} Summary: Average Loss = {avg_loss:.2f}\")\n",
    "            \n",
    "            save_checkpoint(epoch, model, optimizer, scheduler, avg_loss, CONFIG)\n",
    "            early_stopper(avg_loss, model, os.path.join(CONFIG['output_dir'], CONFIG['best_model_filename']))\n",
    "            if early_stopper.early_stop:\n",
    "                print(\"Early stopping triggered.\"); break\n",
    "\n",
    "        print(\"\\n--- Training Finished ---\")\n",
    "        final_encoder_path = os.path.join(CONFIG['output_dir'], \"barlow_final_encoder_50pct.pth\")\n",
    "        torch.save(model.encoder.state_dict(), final_encoder_path)\n",
    "        print(f\"Final encoder saved to {final_encoder_path}\")\n",
    "        print(f\"Best encoder (lowest loss) saved to {os.path.join(CONFIG['output_dir'], CONFIG['best_model_filename'])}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Could not find a valid checkpoint to resume from. Halting execution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3101a9f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 246943226,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 246582072,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-28T23:28:23.423399",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}