{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53947b3c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-22T21:41:37.791840Z",
     "iopub.status.busy": "2025-06-22T21:41:37.791646Z"
    },
    "papermill": {
     "duration": 43200.004865,
     "end_time": "2025-06-23T09:41:37.793284",
     "exception": false,
     "start_time": "2025-06-22T21:41:37.788419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/205.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m204.8/205.4 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.4/205.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/8.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/8.8 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m129.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m129.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/53.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.7/53.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final BYOL Pre-training Script Initialized (50% Data, Stabilized).\n",
      "Using device: cuda\n",
      "Pre-loading images into RAM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e63fa946f34dca8149cad5cff2497b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading files:   0%|          | 0/241 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Initialized: Using 50% of data -> 61,696 images pre-loaded.\n",
      "Using ResNet-18 as the encoder model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting BYOL Training on 50% of Data ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/611832941.py:142: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(device.type == 'cuda'))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "079ac0de2f684ec984da27a83b46df4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/20:   0%|          | 0/482 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/611832941.py:153: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == 'cuda')):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Summary: Average Loss = 0.5797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.579735). Saving best model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd8b8da432e84643b683548e98fb5edc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/20:   0%|          | 0/482 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Summary: Average Loss = 0.3660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.579735 --> 0.365977). Saving best model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d750f322c16541b8a37828ef206ade42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/20:   0%|          | 0/482 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Summary: Average Loss = 0.3033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.365977 --> 0.303293). Saving best model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eee2965f5417419abbd30e24d88c6225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/20:   0%|          | 0/482 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Summary: Average Loss = 0.2823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.303293 --> 0.282252). Saving best model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec64d33c0def4d309c264bf8edd3e77a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/20:   0%|          | 0/482 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Summary: Average Loss = 0.2575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.282252 --> 0.257523). Saving best model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68f333373a69495dafeead19e654ed99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/20:   0%|          | 0/482 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Summary: Average Loss = 0.2438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.257523 --> 0.243777). Saving best model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f67ebc0580e4c9abf02f62c444f448e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/20:   0%|          | 0/482 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Summary: Average Loss = 0.2353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.243777 --> 0.235290). Saving best model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23f931a1930f439e86ef107e51050441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/20:   0%|          | 0/482 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Summary: Average Loss = 0.2268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.235290 --> 0.226837). Saving best model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "171371821e6b491c9c9ed5d0cf48c0bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/20:   0%|          | 0/482 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Summary: Average Loss = 0.2210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.226837 --> 0.221000). Saving best model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c9d683f00347e4aa249d607dcf4e91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/20:   0%|          | 0/482 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Summary: Average Loss = 0.2153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.221000 --> 0.215284). Saving best model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69cecce82957466c8bb97058309183e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/20:   0%|          | 0/482 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Summary: Average Loss = 0.2098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.215284 --> 0.209815). Saving best model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57aa09974ef642d198fab5a0405b15ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/20:   0%|          | 0/482 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Summary: Average Loss = 0.2024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.209815 --> 0.202353). Saving best model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9e17bc0c88d4bd7ad5a84914af2f122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/20:   0%|          | 0/482 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Summary: Average Loss = 0.1987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.202353 --> 0.198735). Saving best model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "013173214b6f4258a389de9c34086004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/20:   0%|          | 0/482 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Summary: Average Loss = 0.1919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.198735 --> 0.191864). Saving best model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e044386d7a7c46589bef4053d8a60f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/20:   0%|          | 0/482 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Summary: Average Loss = 0.1911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.191864 --> 0.191081). Saving best model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e38bdfc77b4849b69ab60a4a150ae298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/20:   0%|          | 0/482 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Summary: Average Loss = 0.1889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.191081 --> 0.188905). Saving best model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6be1c8b2c5544467a00738c34973c39b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/20:   0%|          | 0/482 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 03 - BYOL PRE-TRAINING (v5.0 - FINAL STABLE RUN)\n",
    "# ==============================================================================\n",
    "# Purpose: To train the BYOL model on a large, 50% subset of the dataset\n",
    "#          with all known stability fixes implemented.\n",
    "# ==============================================================================\n",
    "\n",
    "# --- 0. Install and Import ---\n",
    "!pip install \"zarr>=2.10.0\" numcodecs -q\n",
    "\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T, torchvision.models as models\n",
    "from pathlib import Path\n",
    "import numpy as np, zarr, random, math, os, copy, zipfile, tempfile, gc\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "print(\"Final BYOL Pre-training Script Initialized (50% Data, Stabilized).\")\n",
    "\n",
    "# --- 1. Configuration ---\n",
    "CONFIG = {\n",
    "    'data_path': \"/kaggle/input/01-data-preparation/data/ssl4eo-s12/train/S2RGB\",\n",
    "    'output_dir': \"/kaggle/working/\",\n",
    "    'epochs': 20,\n",
    "    'batch_size': 128,\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 1.5e-6,\n",
    "    'image_size': 224,\n",
    "    'projection_dim': 256,\n",
    "    'hidden_dim': 4096,\n",
    "    'base_tau': 0.996,\n",
    "    'num_workers': 2,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'early_stopping_patience': 5,\n",
    "    'data_subset_percentage': 0.50,\n",
    "    'checkpoint_filename': \"byol_checkpoint_50pct.pth\",\n",
    "    'best_model_filename': \"byol_best_encoder_50pct.pth\"\n",
    "}\n",
    "\n",
    "# --- 2. Helper Classes & Functions ---\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=True, delta=0):\n",
    "        self.patience, self.verbose, self.delta = patience, verbose, delta\n",
    "        self.counter, self.best_score, self.early_stop, self.val_loss_min = 0, None, False, np.Inf\n",
    "    def __call__(self, val_loss, model, path):\n",
    "        if not math.isfinite(val_loss): print(\"Loss is not finite, stopping early.\"); self.early_stop = True; return\n",
    "        score = -val_loss\n",
    "        if self.best_score is None: self.best_score = score; self.save_checkpoint(val_loss, model, path)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose: print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience: self.early_stop = True\n",
    "        else: self.best_score = score; self.save_checkpoint(val_loss, model, path); self.counter = 0\n",
    "    def save_checkpoint(self, val_loss, model, path):\n",
    "        if self.verbose: print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving best model...')\n",
    "        torch.save(model.online_encoder.state_dict(), path); self.val_loss_min = val_loss\n",
    "\n",
    "def save_checkpoint(epoch, model, optimizer, scheduler, loss, config):\n",
    "    state = {'epoch': epoch + 1, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), 'scheduler_state_dict': scheduler.state_dict(), 'loss': loss}\n",
    "    torch.save(state, os.path.join(config['output_dir'], config['checkpoint_filename']))\n",
    "\n",
    "def load_checkpoint(model, optimizer, scheduler, config):\n",
    "    path = os.path.join(config['output_dir'], config['checkpoint_filename'])\n",
    "    start_epoch = 0\n",
    "    if os.path.exists(path):\n",
    "        print(f\"Resuming from checkpoint: {path}\")\n",
    "        ckpt = torch.load(path, map_location=config['device'])\n",
    "        model.load_state_dict(ckpt['model_state_dict']); optimizer.load_state_dict(ckpt['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(ckpt['scheduler_state_dict']); start_epoch = ckpt['epoch']\n",
    "    return start_epoch\n",
    "\n",
    "# --- 3. Dataset, Model, and Loss ---\n",
    "class SSL4EODataset(Dataset):\n",
    "    def __init__(self, root_dir, subset_percentage=1.0):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        all_files = sorted(list(self.root_dir.glob(\"*.zarr.zip\")))\n",
    "        num_files = int(len(all_files) * subset_percentage)\n",
    "        self.zarr_files = random.sample(all_files, num_files) if subset_percentage < 1.0 else all_files\n",
    "        self.images = self._preload_images()\n",
    "        print(f\"\\nDataset Initialized: Using {subset_percentage*100:.0f}% of data -> {len(self.images):,} images pre-loaded.\")\n",
    "        self.transform_t = T.Compose([\n",
    "            T.ToPILImage(), T.RandomResizedCrop(CONFIG['image_size'], antialias=True), T.RandomHorizontalFlip(),\n",
    "            T.ColorJitter(0.4, 0.4, 0.2, 0.1), T.RandomGrayscale(p=0.2), T.GaussianBlur(23, (0.1, 2.0)),\n",
    "            T.ToTensor(), T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "        self.transform_t_prime = T.Compose([\n",
    "            T.ToPILImage(), T.RandomResizedCrop(CONFIG['image_size'], antialias=True), T.RandomHorizontalFlip(),\n",
    "            T.ColorJitter(0.4, 0.4, 0.2, 0.1), T.RandomGrayscale(p=0.2), T.RandomSolarize(0.5, p=0.2),\n",
    "            T.ToTensor(), T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "    def _preload_images(self):\n",
    "        images = []; print(\"Pre-loading images into RAM...\")\n",
    "        for fp in tqdm(self.zarr_files, desc=\"Loading files\"):\n",
    "            with tempfile.TemporaryDirectory() as td:\n",
    "                with zipfile.ZipFile(str(fp), 'r') as zf: zf.extractall(td)\n",
    "                za = zarr.open(td, mode='r')['bands'][:]; images.extend(za.reshape(-1, *za.shape[2:]))\n",
    "        return images\n",
    "    def __len__(self): return len(self.images)\n",
    "    def __getitem__(self, idx):\n",
    "        img_chw = self.images[idx]; img_hwc = np.transpose(img_chw, (1, 2, 0))\n",
    "        return self.transform_t(img_hwc), self.transform_t_prime(img_hwc)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, i, h, o): super().__init__(); self.net = nn.Sequential(nn.Linear(i, h), nn.BatchNorm1d(h), nn.ReLU(True), nn.Linear(h, o))\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class BYOLModel(nn.Module):\n",
    "    def __init__(self, encoder, encoder_dim, p_dim, h_dim, b_tau):\n",
    "        super().__init__(); self.base_tau = b_tau\n",
    "        self.online_encoder=encoder; self.online_projector=MLP(encoder_dim,h_dim,p_dim); self.online_predictor=MLP(p_dim,h_dim,p_dim)\n",
    "        self.target_encoder=copy.deepcopy(encoder); self.target_projector=copy.deepcopy(self.online_projector)\n",
    "        for p in self.target_encoder.parameters(): p.requires_grad=False\n",
    "        for p in self.target_projector.parameters(): p.requires_grad=False\n",
    "    @torch.no_grad()\n",
    "    def update_target_network(self, cs, ts):\n",
    "        tau=1-(1-self.base_tau)*(math.cos(math.pi*cs/ts)+1)/2\n",
    "        for o,t in zip(self.online_encoder.parameters(), self.target_encoder.parameters()): t.data.mul_(tau).add_(o.data,alpha=1-tau)\n",
    "        for o,t in zip(self.online_projector.parameters(), self.target_projector.parameters()): t.data.mul_(tau).add_(o.data,alpha=1-tau)\n",
    "    def forward(self, v1, v2):\n",
    "        op1=self.online_predictor(self.online_projector(self.online_encoder(v1))); op2=self.online_predictor(self.online_projector(self.online_encoder(v2)))\n",
    "        with torch.no_grad(): tp1=self.target_projector(self.target_encoder(v1)); tp2=self.target_projector(self.target_encoder(v2))\n",
    "        return (op1, op2), (tp1.detach(), tp2.detach())\n",
    "\n",
    "# MODIFIED: Numerically Stable Loss Function\n",
    "def byol_loss_fn(p, t):\n",
    "    p1, p2 = p; t1, t2 = t\n",
    "    eps = 1e-6\n",
    "    p1_norm = F.normalize(p1, p=2, dim=-1, eps=eps); p2_norm = F.normalize(p2, p=2, dim=-1, eps=eps)\n",
    "    t1_norm = F.normalize(t1.detach(), p=2, dim=-1, eps=eps); t2_norm = F.normalize(t2.detach(), p=2, dim=-1, eps=eps)\n",
    "    loss1 = 2 - 2 * (p1_norm * t2_norm).sum(dim=-1); loss2 = 2 - 2 * (p2_norm * t1_norm).sum(dim=-1)\n",
    "    return (loss1 + loss2).mean() * 0.5\n",
    "\n",
    "# --- 4. Main Training Execution ---\n",
    "device = torch.device(CONFIG['device']); print(f\"Using device: {device}\")\n",
    "dataset = SSL4EODataset(CONFIG['data_path'], CONFIG['data_subset_percentage'])\n",
    "loader = DataLoader(dataset, batch_size=CONFIG['batch_size'], shuffle=True, num_workers=CONFIG['num_workers'], pin_memory=True, drop_last=True)\n",
    "\n",
    "print(\"Using ResNet-18 as the encoder model.\")\n",
    "resnet=models.resnet18(weights=None); ed=resnet.fc.in_features; resnet.fc=nn.Identity()\n",
    "model = BYOLModel(resnet, ed, CONFIG['projection_dim'], CONFIG['hidden_dim'], CONFIG['base_tau']).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=CONFIG['learning_rate'], weight_decay=CONFIG['weight_decay'])\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(loader)*CONFIG['epochs'])\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(device.type == 'cuda'))\n",
    "early_stopper = EarlyStopping(patience=CONFIG['early_stopping_patience'], verbose=True)\n",
    "\n",
    "start_epoch = load_checkpoint(model, optimizer, scheduler, CONFIG)\n",
    "\n",
    "print(f\"\\n--- Starting BYOL Training on {CONFIG['data_subset_percentage']*100:.0f}% of Data ---\")\n",
    "for epoch in range(start_epoch, CONFIG['epochs']):\n",
    "    model.train(); total_loss = 0.0\n",
    "    pbar = tqdm(loader, desc=f\"Epoch {epoch+1}/{CONFIG['epochs']}\")\n",
    "    for v1, v2 in pbar:\n",
    "        v1, v2 = v1.to(device), v2.to(device)\n",
    "        with torch.cuda.amp.autocast(enabled=(device.type == 'cuda')):\n",
    "            p, t = model(v1, v2); loss = byol_loss_fn(p, t)\n",
    "        optimizer.zero_grad(set_to_none=True); scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer); scaler.update(); scheduler.step()\n",
    "        model.update_target_network(epoch*len(loader)+pbar.n, len(loader)*CONFIG['epochs'])\n",
    "        total_loss += loss.item(); pbar.set_postfix({'Loss':f\"{loss.item():.4f}\", 'LR':f\"{optimizer.param_groups[0]['lr']:.6f}\"})\n",
    "    \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    if not math.isfinite(avg_loss): print(f\"Epoch {epoch+1} ended with non-finite loss: {avg_loss}. Stopping.\"); break\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} Summary: Average Loss = {avg_loss:.4f}\")\n",
    "    save_checkpoint(epoch, model, optimizer, scheduler, avg_loss, CONFIG)\n",
    "    early_stopper(avg_loss, model, os.path.join(CONFIG['output_dir'], CONFIG['best_model_filename']))\n",
    "    if early_stopper.early_stop: print(\"Early stopping triggered.\"); break\n",
    "\n",
    "print(\"\\n--- Training Finished ---\")\n",
    "torch.save(model.online_encoder.state_dict(), os.path.join(CONFIG['output_dir'], \"byol_final_encoder_50pct.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148b9aa8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 246856200,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-22T21:41:33.161549",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}